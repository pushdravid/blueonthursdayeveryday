<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Swipe to Open Camera</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      padding: 0;
      height: 100vh;
      width: 100vw;
      display: flex;
      justify-content: center;
      align-items: center;
      background-color: #000;
      color: #fff;
      font-family: sans-serif;
      text-align: center;
      overflow: hidden;
      position: relative;
    }

    #content {
      z-index: 10;
      position: absolute;
      top: 20px;
      width: 100%;
      pointer-events: none;
    }

    #video,
    #canvas {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      z-index: 5;
    }

    #video {
      display: none;
    }
    #overlay {
      position: fixed;
      bottom: 0;
      width: 100%;
      padding: 10px;
      background-color: rgba(0, 0, 0, 0.6);
      color: #ffcc00;
      text-align: center;
      font-size: 14px;
      z-index: 20;
      pointer-events: none;
      line-height: 1.4;
      font-family: monospace;
    }
  </style>
</head>
<body>
  <div id="content">
    <h1>Swipe up to open camera</h1>
    <p>Shifa's POV: Thursday</p>
  </div>

  <video id="video" autoplay muted playsinline width="640" height="480"></video>
  <canvas id="canvas"></canvas>

  <!-- ðŸ†• Overlay message -->
  <div id="overlay">
    Vibe coded<br />Works like 48% of the time
  </div>

  <!-- TensorFlow.js & BodyPix -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.0.5"></script>

  <script>
    let touchStartY = 0;
    let touchEndY = 0;
    let running = false;
    let errorCount = 0;

    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    let net;

    document.body.addEventListener('touchstart', (e) => {
      touchStartY = e.changedTouches[0].screenY;
    });

    document.body.addEventListener('touchend', (e) => {
      touchEndY = e.changedTouches[0].screenY;
      if (touchStartY - touchEndY > 50 && !running) {
        running = true;
        document.getElementById('content').style.display = 'none';
        main();
      }
    });

    async function setupCamera() {
      console.log('Requesting camera access...');
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
        video.srcObject = stream;

        return new Promise((resolve) => {
          video.onloadedmetadata = () => {
            console.log('Video metadata loaded.');
            console.log(`Video readyState: ${video.readyState}`);
            console.log(`Video dimensions: ${video.videoWidth} x ${video.videoHeight}`);

            // Set canvas resolution to match video
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            resolve(video);
          };
        });
      } catch (err) {
        console.error('Camera error:', err);
        alert('Camera access denied or failed.');
        throw err;
      }
    }

    async function main() {
      try {
        await tf.setBackend('webgl');
        await tf.ready();
        console.log('TensorFlow.js ready with backend:', tf.getBackend());

        net = await bodyPix.load({
          architecture: 'MobileNetV1',
          outputStride: 16,
          multiplier: 0.5,
        });
        console.log('BodyPix model loaded');
      } catch (err) {
        console.error('Initialization error:', err);
        return;
      }

      try {
        await setupCamera();
        await video.play();
        video.style.display = 'block';
      } catch (e) {
        console.warn('Video setup failed:', e);
        return;
      }

      function renderFrame() {
        if (
          video.readyState >= 2 &&
          video.videoWidth > 0 &&
          video.videoHeight > 0
        ) {
          try {
            net.segmentPersonParts(video, {
              internalResolution: 'medium',
              segmentationThreshold: 0.7,
            }).then((segmentation) => {
              errorCount = 0;

              ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
              const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
              const { data } = imageData;

              for (let i = 0; i < segmentation.data.length; i++) {
                if (segmentation.data[i] === 11 || segmentation.data[i] === 12) {
                  const j = i * 4;
                  data[j] = 0;
                  data[j + 1] = 0;
                  data[j + 2] = 255;
                  data[j + 3] = 180;
                }
              }

              ctx.putImageData(imageData, 0, 0);
              requestAnimationFrame(renderFrame);
            }).catch((error) => {
              handleSegmentationError(error);
            });
          } catch (error) {
            handleSegmentationError(error);
          }
        } else {
          console.warn('Video not ready, skipping frame...');
          requestAnimationFrame(renderFrame);
        }
      }

      function handleSegmentationError(error) {
        errorCount++;
        console.error(`Segmentation error #${errorCount}:`, error);
        if (error && error.stack) console.error('Stack trace:', error.stack);

        if (errorCount > 5) {
          console.warn('Too many errors. Pausing...');
          setTimeout(() => {
            errorCount = 0;
            requestAnimationFrame(renderFrame);
          }, 1000);
        } else {
          requestAnimationFrame(renderFrame);
        }
      }

      renderFrame();
    }
  </script>
</body>
</html>
